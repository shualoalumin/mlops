{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ffcee4185642b9acaf47e27c3aadee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28e344fa80945248996ea9451242917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876abaa881ff4b98834778c40bc71854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36867b5ebbed4c2e84344968adab747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) 토크나이저 & 모델 불러오기\n",
    "TOKENIZER_NAME = \"skt/kogpt2-base-v2\"\n",
    "MODEL_NAME = \"skt/kogpt2-base-v2\"\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    TOKENIZER_NAME,\n",
    "    bos_token='<s>',\n",
    "    eos_token='</s>',\n",
    "    unk_token='<unk>',\n",
    "    pad_token='<pad>',\n",
    "    mask_token='<mask>'\n",
    ")\n",
    "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 텍스트 생성 함수 정의\n",
    "def generate_text(prompt, max_length=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    # 모델의 generate 함수 사용\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        num_beams=5,        # 빔 서치 사용 시\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕! 요즘 어때?\"\n",
      "\"아니야. 괜찮아.\"\n",
      "\"그렇지. 그게 무슨 소리야? 그건 그렇고 그걸로 끝이지.\"\n",
      "그녀는 고개를 끄덕였다.\n",
      "\"어떻게 된 거\n"
     ]
    }
   ],
   "source": [
    "# 3) 테스트\n",
    "prompt = \"안녕! 요즘 어때?\"\n",
    "result = generate_text(prompt, max_length=50)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇과 대화를 시작합니다. (종료하려면 'quit' 또는 '종료'를 입력하세요)\n",
      "==================================================\n",
      "챗봇: 왓츠앱\n",
      "카카오톡: 인스타그램\n",
      "페이스북: 트위터\n",
      "미투데이: 유튜브\n",
      "네이버TV: 미투데이, 네이버블로그\n",
      "다음커뮤니케이션즈: 다음TV\n",
      "SK텔레콤: SK브로드밴드\n",
      "LG유플러스: LG헬로비전\n",
      "KT는 LG유플러스를 통해 가입자를 모집하고 있다.\n",
      "KB국민은행\n"
     ]
    }
   ],
   "source": [
    "# 3) 대화형 테스트 함수\n",
    "def chat():\n",
    "    print(\"챗봇과 대화를 시작합니다. (종료하려면 'quit' 또는 '종료'를 입력하세요)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    context = \"\"  # 대화 맥락 유지\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\n사용자: \")\n",
    "        \n",
    "        if user_input.lower() in ['quit', '종료']:\n",
    "            print(\"\\n대화를 종료합니다.\")\n",
    "            break\n",
    "            \n",
    "        # 이전 대화 맥락을 포함하여 프롬프트 생성\n",
    "        if context:\n",
    "            prompt = f\"{context}\\n사용자: {user_input}\\n챗봇:\"\n",
    "        else:\n",
    "            prompt = f\"사용자: {user_input}\\n챗봇:\"\n",
    "            \n",
    "        try:\n",
    "            response = generate_text(prompt, max_length=100)\n",
    "            \n",
    "            # 응답에서 필요한 부분만 추출\n",
    "            if \"챗봇:\" in response:\n",
    "                response = response.split(\"챗봇:\")[-1].strip()\n",
    "            \n",
    "            print(f\"챗봇: {response}\")\n",
    "            \n",
    "            # 대화 맥락 업데이트 (최근 2턴만 유지)\n",
    "            context = f\"{prompt} {response}\"\n",
    "            if len(context.split('\\n')) > 4:\n",
    "                context = '\\n'.join(context.split('\\n')[-4:])\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"오류가 발생했습니다: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# 대화형 테스트 실행\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
