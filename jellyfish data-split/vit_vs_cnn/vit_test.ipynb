{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) 라이브러리 임포트 / Import Libraries\n",
    "**[KOR]** 이 셀에서는 전체 파이프라인에 필요한 라이브러리를 임포트합니다.\n",
    "**[ENG]** This cell imports all libraries required for the entire pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Hugging Face 관련 라이브러리 / Hugging Face libraries\n",
    "from transformers import (ViTImageProcessor, ViTForImageClassification,\n",
    "                          TFViTModel, create_optimizer, TrainingArguments, Trainer,\n",
    "                          DefaultDataCollator)\n",
    "\n",
    "# W&B / Weights & Biases\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "# 기타 / Others\n",
    "import numpy as np\n",
    "import os\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) W&B 프로젝트 초기화 / Initialize W&B\n",
    "**[KOR]** 여기서는 W&B 프로젝트를 초기화합니다. 원하는 프로젝트 이름과 실험명을 지정할 수 있습니다.\n",
    "**[ENG]** Here, we initialize a W&B project. Customize the project name and run name as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: realx1212 (realx1212-aijosh). Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\GitHub\\mlops\\wandb\\run-20250125_155032-cmpy0jtt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/cmpy0jtt' target=\"_blank\">Initial_Run</a></strong> to <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/cmpy0jtt' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/cmpy0jtt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/cmpy0jtt?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x26a5109ad10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"ViT_vs_CNN_jellyfish\", \n",
    "    name=\"Initial_Run\", \n",
    "    reinit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) 데이터셋 로드 및 전처리 / Load and Preprocess the Dataset\n",
    "**[KOR]** 이 부분만 기존 tf_flowers 대신, Google Drive 경로에 있는 local dataset(jellyfish 등)을 로드하는 코드로 변경합니다. \n",
    "**[ENG]** This section is modified to load a local dataset (e.g., jellyfish) from a Google Drive path instead of tf_flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 427 files belonging to 6 classes.\n",
      "Found 51 files belonging to 6 classes.\n",
      "Found 56 files belonging to 6 classes.\n",
      "Classes: ['barrel_jellyfish', 'blue_jellyfish', 'compass_jellyfish', 'lions_mane_jellyfish', 'mauve_stinger_jellyfish', 'moon_jellyfish']\n",
      "num_classes: 6\n",
      "train batch shape: (32, 224, 224, 3)\n",
      "Batch 0 shape: (32, 224, 224, 3)\n",
      "Labels 0 shape: (32,)\n",
      "Batch 1 shape: (32, 224, 224, 3)\n",
      "Labels 1 shape: (32,)\n",
      "Batch 2 shape: (32, 224, 224, 3)\n",
      "Labels 2 shape: (32,)\n",
      "Batch 3 shape: (32, 224, 224, 3)\n",
      "Labels 3 shape: (32,)\n",
      "Batch 4 shape: (32, 224, 224, 3)\n",
      "Labels 4 shape: (32,)\n",
      "Batch 5 shape: (32, 224, 224, 3)\n",
      "Labels 5 shape: (32,)\n",
      "Batch 6 shape: (32, 224, 224, 3)\n",
      "Labels 6 shape: (32,)\n",
      "Batch 7 shape: (32, 224, 224, 3)\n",
      "Labels 7 shape: (32,)\n",
      "Batch 8 shape: (32, 224, 224, 3)\n",
      "Labels 8 shape: (32,)\n",
      "Batch 9 shape: (32, 224, 224, 3)\n",
      "Labels 9 shape: (32,)\n",
      "Val Batch 0 shape: (32, 224, 224, 3)\n",
      "Val Batch 1 shape: (19, 224, 224, 3)\n",
      "Test Batch 0 shape: (32, 224, 224, 3)\n",
      "Test Batch 1 shape: (24, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "data_path = r\"C:\\Users\\User\\Documents\\GitHub\\National_OceanoGraphic\\dataset\\3_classweight80\"\n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "\n",
    "# train/ val/ test/ 디렉토리가 이미 존재한다고 가정\n",
    "train_dir = os.path.join(data_path, 'train')\n",
    "val_dir = os.path.join(data_path, 'val')\n",
    "test_dir = os.path.join(data_path, 'test')\n",
    "\n",
    "def preprocess_image_ds(ds):\n",
    "    # 데이터 증강, 정규화를 진행하지만, 여기서는 배치 X\n",
    "    ds = ds.map(lambda x, y: (tf.image.resize(x, img_size), y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(lambda x, y: (x / 255.0, y),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # 배치와 prefetch는 image_dataset_from_directory에서 이미 배치되었으므로 제거\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# 이미 batch_size=32로 dataset을 생성\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='int',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    label_mode='int',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='int',\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# 이제 preprocess_image_ds에서는 배치를 다시 하지 않음\n",
    "train_batches = preprocess_image_ds(train_ds)\n",
    "val_batches   = preprocess_image_ds(val_ds)\n",
    "test_batches  = preprocess_image_ds(test_ds)\n",
    "\n",
    "# 클래스 개수 파악\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"num_classes:\", num_classes)\n",
    "\n",
    "# shape 확인 (예시)\n",
    "for images, labels in train_batches.take(1):\n",
    "    print(\"train batch shape:\", images.shape)  # (32, 224, 224, 3) 형태가 되어야 함\n",
    "\n",
    "for i, (images, labels) in enumerate(train_batches):\n",
    "    print(f\"Batch {i} shape:\", images.shape)\n",
    "    # 필요하다면 라벨 shape도 확인\n",
    "    print(f\"Labels {i} shape:\", labels.shape)\n",
    "    \n",
    "    # 10개 배치만 확인 (예시)\n",
    "    if i >= 9:\n",
    "        break\n",
    "\n",
    "for i, (images, labels) in enumerate(val_batches):\n",
    "    print(f\"Val Batch {i} shape:\", images.shape)\n",
    "    if i >= 2:\n",
    "        break\n",
    "\n",
    "for i, (images, labels) in enumerate(test_batches):\n",
    "    print(f\"Test Batch {i} shape:\", images.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) 간단 CNN 모델 정의 / Define a Simple CNN Model\n",
    "**[KOR]** 전통적인 CNN 모델과 비교하기 위해, 간단한 Conv-BN-MaxPool 구조의 CNN 모델을 정의합니다.\n",
    "**[ENG]** Define a simple CNN model (Conv-BN-MaxPool architecture) for comparison with the ViT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_cnn(num_classes):\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3), name=\"input_images\")\n",
    "    x = tf.keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = tf.keras.layers.Conv2D(128, 3, activation='relu')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) CNN 모델 훈련 / Train the CNN Model\n",
    "**[KOR]** 간단 CNN 모델을 학습시키고 W&B에 로깅합니다. CNN 성능을 파악한 뒤, 이후 ViT와 비교할 수 있습니다.\n",
    "**[ENG]** Train the simple CNN model and log metrics to W&B. We can then compare its performance to the ViT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e787c034392a4f2a8bd6008f9424d7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\GitHub\\mlops\\wandb\\run-20250125_161115-2xmvyzrs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/2xmvyzrs' target=\"_blank\">CNN_flowers_run</a></strong> to <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/2xmvyzrs' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/2xmvyzrs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 18s 1s/step - accuracy: 0.2500 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 4s 412ms/step - accuracy: 0.2578 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 4s 416ms/step - accuracy: 0.2413 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 4s 418ms/step - accuracy: 0.2279 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 3s 435ms/step - accuracy: 0.2223 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 3s 435ms/step - accuracy: 0.2174 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 3s 436ms/step - accuracy: 0.2150 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 2s 433ms/step - accuracy: 0.2121 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 2s 432ms/step - accuracy: 0.2086 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 1s 433ms/step - accuracy: 0.2061 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 1s 436ms/step - accuracy: 0.2050 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 0s 444ms/step - accuracy: 0.2050 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 0s 441ms/step - accuracy: 0.2042 - loss: 1.77 ━━━━━━━━━━━━━━━━━━━━ 0s 418ms/step - accuracy: 0.2034 - loss: 1.77 ━━━━━━━━━━━━━━━━━━━━ 8s 467ms/step - accuracy: 0.2026 - loss: 1.7791 - val_accuracy: 0.2157 - val_loss: 1.7307\n",
      "Epoch 2/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 6s 537ms/step - accuracy: 0.0625 - loss: 1.78 ━━━━━━━━━━━━━━━━━━━━ 4s 409ms/step - accuracy: 0.1094 - loss: 1.77 ━━━━━━━━━━━━━━━━━━━━ 4s 410ms/step - accuracy: 0.1354 - loss: 1.77 ━━━━━━━━━━━━━━━━━━━━ 4s 408ms/step - accuracy: 0.1504 - loss: 1.76 ━━━━━━━━━━━━━━━━━━━━ 3s 409ms/step - accuracy: 0.1578 - loss: 1.76 ━━━━━━━━━━━━━━━━━━━━ 3s 408ms/step - accuracy: 0.1654 - loss: 1.76 ━━━━━━━━━━━━━━━━━━━━ 2s 410ms/step - accuracy: 0.1704 - loss: 1.76 ━━━━━━━━━━━━━━━━━━━━ 2s 414ms/step - accuracy: 0.1750 - loss: 1.75 ━━━━━━━━━━━━━━━━━━━━ 2s 419ms/step - accuracy: 0.1803 - loss: 1.75 ━━━━━━━━━━━━━━━━━━━━ 1s 420ms/step - accuracy: 0.1854 - loss: 1.75 ━━━━━━━━━━━━━━━━━━━━ 1s 420ms/step - accuracy: 0.1894 - loss: 1.75 ━━━━━━━━━━━━━━━━━━━━ 0s 419ms/step - accuracy: 0.1923 - loss: 1.75 ━━━━━━━━━━━━━━━━━━━━ 0s 420ms/step - accuracy: 0.1949 - loss: 1.75 ━━━━━━━━━━━━━━━━━━━━ 0s 398ms/step - accuracy: 0.1972 - loss: 1.75 ━━━━━━━━━━━━━━━━━━━━ 6s 439ms/step - accuracy: 0.1992 - loss: 1.7515 - val_accuracy: 0.2745 - val_loss: 1.6627\n",
      "Epoch 3/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 7s 539ms/step - accuracy: 0.1875 - loss: 1.75 ━━━━━━━━━━━━━━━━━━━━ 4s 407ms/step - accuracy: 0.2266 - loss: 1.73 ━━━━━━━━━━━━━━━━━━━━ 4s 413ms/step - accuracy: 0.2587 - loss: 1.71 ━━━━━━━━━━━━━━━━━━━━ 4s 407ms/step - accuracy: 0.2663 - loss: 1.70 ━━━━━━━━━━━━━━━━━━━━ 3s 411ms/step - accuracy: 0.2668 - loss: 1.69 ━━━━━━━━━━━━━━━━━━━━ 3s 410ms/step - accuracy: 0.2674 - loss: 1.69 ━━━━━━━━━━━━━━━━━━━━ 2s 420ms/step - accuracy: 0.2669 - loss: 1.69 ━━━━━━━━━━━━━━━━━━━━ 2s 419ms/step - accuracy: 0.2657 - loss: 1.69 ━━━━━━━━━━━━━━━━━━━━ 2s 421ms/step - accuracy: 0.2651 - loss: 1.68 ━━━━━━━━━━━━━━━━━━━━ 1s 419ms/step - accuracy: 0.2649 - loss: 1.68 ━━━━━━━━━━━━━━━━━━━━ 1s 418ms/step - accuracy: 0.2648 - loss: 1.68 ━━━━━━━━━━━━━━━━━━━━ 0s 419ms/step - accuracy: 0.2655 - loss: 1.68 ━━━━━━━━━━━━━━━━━━━━ 0s 419ms/step - accuracy: 0.2653 - loss: 1.68 ━━━━━━━━━━━━━━━━━━━━ 0s 397ms/step - accuracy: 0.2647 - loss: 1.68 ━━━━━━━━━━━━━━━━━━━━ 6s 436ms/step - accuracy: 0.2642 - loss: 1.6824 - val_accuracy: 0.3922 - val_loss: 1.5754\n",
      "Epoch 4/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 6s 517ms/step - accuracy: 0.2188 - loss: 1.68 ━━━━━━━━━━━━━━━━━━━━ 4s 412ms/step - accuracy: 0.2578 - loss: 1.64 ━━━━━━━━━━━━━━━━━━━━ 4s 420ms/step - accuracy: 0.2830 - loss: 1.62 ━━━━━━━━━━━━━━━━━━━━ 4s 428ms/step - accuracy: 0.2962 - loss: 1.62 ━━━━━━━━━━━━━━━━━━━━ 3s 438ms/step - accuracy: 0.3082 - loss: 1.62 ━━━━━━━━━━━━━━━━━━━━ 3s 439ms/step - accuracy: 0.3141 - loss: 1.62 ━━━━━━━━━━━━━━━━━━━━ 3s 447ms/step - accuracy: 0.3177 - loss: 1.62 ━━━━━━━━━━━━━━━━━━━━ 2s 451ms/step - accuracy: 0.3200 - loss: 1.62 ━━━━━━━━━━━━━━━━━━━━ 2s 457ms/step - accuracy: 0.3219 - loss: 1.61 ━━━━━━━━━━━━━━━━━━━━ 1s 457ms/step - accuracy: 0.3216 - loss: 1.61 ━━━━━━━━━━━━━━━━━━━━ 1s 460ms/step - accuracy: 0.3220 - loss: 1.61 ━━━━━━━━━━━━━━━━━━━━ 0s 460ms/step - accuracy: 0.3230 - loss: 1.61 ━━━━━━━━━━━━━━━━━━━━ 0s 462ms/step - accuracy: 0.3236 - loss: 1.61 ━━━━━━━━━━━━━━━━━━━━ 0s 438ms/step - accuracy: 0.3243 - loss: 1.61 ━━━━━━━━━━━━━━━━━━━━ 7s 478ms/step - accuracy: 0.3248 - loss: 1.6184 - val_accuracy: 0.3922 - val_loss: 1.5243\n",
      "Epoch 5/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 8s 653ms/step - accuracy: 0.4375 - loss: 1.57 ━━━━━━━━━━━━━━━━━━━━ 5s 448ms/step - accuracy: 0.4062 - loss: 1.55 ━━━━━━━━━━━━━━━━━━━━ 4s 445ms/step - accuracy: 0.3889 - loss: 1.54 ━━━━━━━━━━━━━━━━━━━━ 4s 443ms/step - accuracy: 0.3854 - loss: 1.53 ━━━━━━━━━━━━━━━━━━━━ 3s 435ms/step - accuracy: 0.3821 - loss: 1.53 ━━━━━━━━━━━━━━━━━━━━ 3s 450ms/step - accuracy: 0.3766 - loss: 1.54 ━━━━━━━━━━━━━━━━━━━━ 3s 451ms/step - accuracy: 0.3687 - loss: 1.55 ━━━━━━━━━━━━━━━━━━━━ 2s 447ms/step - accuracy: 0.3622 - loss: 1.55 ━━━━━━━━━━━━━━━━━━━━ 2s 447ms/step - accuracy: 0.3582 - loss: 1.55 ━━━━━━━━━━━━━━━━━━━━ 1s 447ms/step - accuracy: 0.3558 - loss: 1.55 ━━━━━━━━━━━━━━━━━━━━ 1s 445ms/step - accuracy: 0.3534 - loss: 1.55 ━━━━━━━━━━━━━━━━━━━━ 0s 443ms/step - accuracy: 0.3515 - loss: 1.56 ━━━━━━━━━━━━━━━━━━━━ 0s 443ms/step - accuracy: 0.3502 - loss: 1.56 ━━━━━━━━━━━━━━━━━━━━ 0s 420ms/step - accuracy: 0.3493 - loss: 1.56 ━━━━━━━━━━━━━━━━━━━━ 7s 459ms/step - accuracy: 0.3485 - loss: 1.5650 - val_accuracy: 0.3529 - val_loss: 1.5533\n",
      "Epoch 6/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 7s 544ms/step - accuracy: 0.3750 - loss: 1.59 ━━━━━━━━━━━━━━━━━━━━ 5s 420ms/step - accuracy: 0.3594 - loss: 1.60 ━━━━━━━━━━━━━━━━━━━━ 4s 430ms/step - accuracy: 0.3403 - loss: 1.61 ━━━━━━━━━━━━━━━━━━━━ 4s 447ms/step - accuracy: 0.3314 - loss: 1.60 ━━━━━━━━━━━━━━━━━━━━ 3s 442ms/step - accuracy: 0.3251 - loss: 1.60 ━━━━━━━━━━━━━━━━━━━━ 3s 442ms/step - accuracy: 0.3273 - loss: 1.60 ━━━━━━━━━━━━━━━━━━━━ 3s 447ms/step - accuracy: 0.3278 - loss: 1.60 ━━━━━━━━━━━━━━━━━━━━ 2s 446ms/step - accuracy: 0.3288 - loss: 1.59 ━━━━━━━━━━━━━━━━━━━━ 2s 447ms/step - accuracy: 0.3297 - loss: 1.59 ━━━━━━━━━━━━━━━━━━━━ 1s 451ms/step - accuracy: 0.3308 - loss: 1.59 ━━━━━━━━━━━━━━━━━━━━ 1s 447ms/step - accuracy: 0.3309 - loss: 1.58 ━━━━━━━━━━━━━━━━━━━━ 0s 444ms/step - accuracy: 0.3307 - loss: 1.58 ━━━━━━━━━━━━━━━━━━━━ 0s 443ms/step - accuracy: 0.3300 - loss: 1.58 ━━━━━━━━━━━━━━━━━━━━ 0s 420ms/step - accuracy: 0.3299 - loss: 1.58 ━━━━━━━━━━━━━━━━━━━━ 7s 460ms/step - accuracy: 0.3297 - loss: 1.5807 - val_accuracy: 0.3922 - val_loss: 1.4457\n",
      "Epoch 7/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 6s 527ms/step - accuracy: 0.4062 - loss: 1.45 ━━━━━━━━━━━━━━━━━━━━ 5s 419ms/step - accuracy: 0.3750 - loss: 1.50 ━━━━━━━━━━━━━━━━━━━━ 4s 422ms/step - accuracy: 0.3819 - loss: 1.50 ━━━━━━━━━━━━━━━━━━━━ 4s 452ms/step - accuracy: 0.3841 - loss: 1.50 ━━━━━━━━━━━━━━━━━━━━ 4s 455ms/step - accuracy: 0.3823 - loss: 1.50 ━━━━━━━━━━━━━━━━━━━━ 3s 448ms/step - accuracy: 0.3819 - loss: 1.51 ━━━━━━━━━━━━━━━━━━━━ 3s 458ms/step - accuracy: 0.3797 - loss: 1.51 ━━━━━━━━━━━━━━━━━━━━ 2s 467ms/step - accuracy: 0.3801 - loss: 1.52 ━━━━━━━━━━━━━━━━━━━━ 2s 459ms/step - accuracy: 0.3822 - loss: 1.51 ━━━━━━━━━━━━━━━━━━━━ 1s 454ms/step - accuracy: 0.3852 - loss: 1.51 ━━━━━━━━━━━━━━━━━━━━ 1s 452ms/step - accuracy: 0.3869 - loss: 1.51 ━━━━━━━━━━━━━━━━━━━━ 0s 450ms/step - accuracy: 0.3887 - loss: 1.51 ━━━━━━━━━━━━━━━━━━━━ 0s 448ms/step - accuracy: 0.3903 - loss: 1.50 ━━━━━━━━━━━━━━━━━━━━ 0s 425ms/step - accuracy: 0.3911 - loss: 1.50 ━━━━━━━━━━━━━━━━━━━━ 7s 464ms/step - accuracy: 0.3919 - loss: 1.5082 - val_accuracy: 0.4118 - val_loss: 1.3747\n",
      "Epoch 8/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 6s 522ms/step - accuracy: 0.4688 - loss: 1.38 ━━━━━━━━━━━━━━━━━━━━ 4s 398ms/step - accuracy: 0.4453 - loss: 1.40 ━━━━━━━━━━━━━━━━━━━━ 4s 409ms/step - accuracy: 0.4288 - loss: 1.42 ━━━━━━━━━━━━━━━━━━━━ 4s 408ms/step - accuracy: 0.4193 - loss: 1.44 ━━━━━━━━━━━━━━━━━━━━ 3s 407ms/step - accuracy: 0.4117 - loss: 1.45 ━━━━━━━━━━━━━━━━━━━━ 3s 409ms/step - accuracy: 0.4082 - loss: 1.46 ━━━━━━━━━━━━━━━━━━━━ 2s 422ms/step - accuracy: 0.4053 - loss: 1.46 ━━━━━━━━━━━━━━━━━━━━ 2s 425ms/step - accuracy: 0.4040 - loss: 1.46 ━━━━━━━━━━━━━━━━━━━━ 2s 427ms/step - accuracy: 0.4023 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 1s 425ms/step - accuracy: 0.4005 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 1s 422ms/step - accuracy: 0.3987 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 0s 420ms/step - accuracy: 0.3976 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 0s 420ms/step - accuracy: 0.3973 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 0s 398ms/step - accuracy: 0.3971 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 6s 436ms/step - accuracy: 0.3968 - loss: 1.4790 - val_accuracy: 0.4706 - val_loss: 1.4016\n",
      "Epoch 9/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 6s 527ms/step - accuracy: 0.3438 - loss: 1.54 ━━━━━━━━━━━━━━━━━━━━ 5s 426ms/step - accuracy: 0.3750 - loss: 1.48 ━━━━━━━━━━━━━━━━━━━━ 4s 426ms/step - accuracy: 0.3889 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 4s 422ms/step - accuracy: 0.3952 - loss: 1.46 ━━━━━━━━━━━━━━━━━━━━ 3s 423ms/step - accuracy: 0.3961 - loss: 1.46 ━━━━━━━━━━━━━━━━━━━━ 3s 422ms/step - accuracy: 0.3970 - loss: 1.46 ━━━━━━━━━━━━━━━━━━━━ 2s 423ms/step - accuracy: 0.3970 - loss: 1.46 ━━━━━━━━━━━━━━━━━━━━ 2s 424ms/step - accuracy: 0.3972 - loss: 1.46 ━━━━━━━━━━━━━━━━━━━━ 2s 438ms/step - accuracy: 0.3959 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 1s 435ms/step - accuracy: 0.3950 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 1s 433ms/step - accuracy: 0.3945 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 0s 432ms/step - accuracy: 0.3942 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 0s 433ms/step - accuracy: 0.3940 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 0s 411ms/step - accuracy: 0.3938 - loss: 1.47 ━━━━━━━━━━━━━━━━━━━━ 6s 451ms/step - accuracy: 0.3936 - loss: 1.4701 - val_accuracy: 0.4706 - val_loss: 1.3525\n",
      "Epoch 10/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 7s 571ms/step - accuracy: 0.4375 - loss: 1.43 ━━━━━━━━━━━━━━━━━━━━ 4s 404ms/step - accuracy: 0.4766 - loss: 1.36 ━━━━━━━━━━━━━━━━━━━━ 4s 448ms/step - accuracy: 0.4948 - loss: 1.33 ━━━━━━━━━━━━━━━━━━━━ 4s 459ms/step - accuracy: 0.5059 - loss: 1.31 ━━━━━━━━━━━━━━━━━━━━ 4s 449ms/step - accuracy: 0.5072 - loss: 1.31 ━━━━━━━━━━━━━━━━━━━━ 3s 438ms/step - accuracy: 0.5043 - loss: 1.32 ━━━━━━━━━━━━━━━━━━━━ 3s 431ms/step - accuracy: 0.5005 - loss: 1.32 ━━━━━━━━━━━━━━━━━━━━ 2s 426ms/step - accuracy: 0.4950 - loss: 1.33 ━━━━━━━━━━━━━━━━━━━━ 2s 425ms/step - accuracy: 0.4898 - loss: 1.34 ━━━━━━━━━━━━━━━━━━━━ 1s 427ms/step - accuracy: 0.4868 - loss: 1.34 ━━━━━━━━━━━━━━━━━━━━ 1s 433ms/step - accuracy: 0.4846 - loss: 1.34 ━━━━━━━━━━━━━━━━━━━━ 0s 436ms/step - accuracy: 0.4835 - loss: 1.35 ━━━━━━━━━━━━━━━━━━━━ 0s 435ms/step - accuracy: 0.4820 - loss: 1.35 ━━━━━━━━━━━━━━━━━━━━ 0s 413ms/step - accuracy: 0.4810 - loss: 1.36 ━━━━━━━━━━━━━━━━━━━━ 6s 452ms/step - accuracy: 0.4802 - loss: 1.3635 - val_accuracy: 0.4510 - val_loss: 1.3550\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 0s 139ms/step - accuracy: 0.3750 - loss: 1.36 ━━━━━━━━━━━━━━━━━━━━ 0s 82ms/step - accuracy: 0.3482 - loss: 1.3925 ━━━━━━━━━━━━━━━━━━━━ 0s 88ms/step - accuracy: 0.3393 - loss: 1.4013\n",
      "CNN Test Evaluation: [1.4186784029006958, 0.3214285671710968]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▅▅▄▆▆▆█</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▄▄▃▃▂▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▃▆▆▅▆▆██▇</td></tr><tr><td>epoch/val_loss</td><td>█▇▅▄▅▃▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.46838</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>1.40162</td></tr><tr><td>epoch/val_accuracy</td><td>0.45098</td></tr><tr><td>epoch/val_loss</td><td>1.355</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">CNN_flowers_run</strong> at: <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/2xmvyzrs' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/2xmvyzrs</a><br> View project at: <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250125_161115-2xmvyzrs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN model\n",
    "cnn_model = create_simple_cnn(num_classes)\n",
    "\n",
    "wandb.init(\n",
    "    project=\"ViT_vs_CNN_jellyfish\", \n",
    "    name=\"CNN_flowers_run\", \n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_model.fit(\n",
    "    train_batches,\n",
    "    validation_data=val_batches,\n",
    "    epochs=10,  # 예시로 3 epoch\n",
    "     callbacks=[WandbMetricsLogger(log_freq=\"epoch\"),WandbModelCheckpoint(\"model_checkpoint.keras\")] \n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "cnn_eval = cnn_model.evaluate(test_batches)\n",
    "print(\"CNN Test Evaluation:\", cnn_eval)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5996fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFViTModel\n",
    "\n",
    "class TFPixelValuesWrapper(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"google/vit-base-patch16-224-in21k\",\n",
    "        base_trainable=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        # 사전 학습된 TFViTModel 로드\n",
    "        self.base_vit = TFViTModel.from_pretrained(model_name)\n",
    "        self.base_vit.trainable = base_trainable\n",
    "        \n",
    "        self.hidden_size = self.base_vit.config.hidden_size\n",
    "        self.patch_size  = self.base_vit.config.patch_size\n",
    "        self.image_size  = self.base_vit.config.image_size\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        \"\"\"\n",
    "        inputs: (batch, 224, 224, 3)\n",
    "        TFViTModel expects pixel_values in (batch, channels, height, width) or just a normal tf.Tensor.\n",
    "        \"\"\"\n",
    "        # KerasTensor -> 실제 텐서 변환 + transpose (channels-last → channels-first)\n",
    "        pixel_values = tf.transpose(inputs, perm=[0, 3, 1, 2])  # (B, 3, 224, 224)\n",
    "\n",
    "        outputs = self.base_vit(pixel_values=pixel_values, training=training)\n",
    "        # 예: outputs.last_hidden_state (B, seq_len, hidden_dim)\n",
    "        return outputs.last_hidden_state\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # (batch, 224, 224, 3)\n",
    "        # seq_len = (224/patch_size)*(224/patch_size)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = (self.image_size // self.patch_size) * (self.image_size // self.patch_size)\n",
    "        return (batch_size, seq_len, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Functional API 기반 ViT 모델 빌드 함수 / Build ViT Model with Functional API\n",
    "**[KOR]** 사전 학습된 ViT를 불러와, Dense와 Dropout, BatchNorm 등을 파라미터로 동적으로 추가/조절하는 함수를 만듭니다.\n",
    "**[ENG]** Load a pretrained ViT, then add Dense, Dropout, and BatchNorm layers dynamically based on hyperparameters in a build function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vit_model(\n",
    "    num_classes,\n",
    "    num_dense_layers=1,\n",
    "    dense_units=128,\n",
    "    dropout_rate=0.3,\n",
    "    use_batchnorm=True,\n",
    "    base_trainable=False\n",
    "):\n",
    "    # (224, 224, 3) 입력\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3), name=\"input_images\")\n",
    "\n",
    "    # 래퍼 레이어 인스턴스\n",
    "    vit_layer = TFPixelValuesWrapper(\n",
    "        model_name=\"google/vit-base-patch16-224-in21k\",\n",
    "        base_trainable=base_trainable\n",
    "    )\n",
    "\n",
    "    # ViT 출력: (batch, seq_len, hidden_dim)\n",
    "    vit_outputs = vit_layer(inputs)\n",
    "\n",
    "    # seq_len 차원 풀링\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(vit_outputs)\n",
    "\n",
    "    # 추가 Dense 레이어 쌓기\n",
    "    for _ in range(num_dense_layers):\n",
    "        x = tf.keras.layers.Dense(dense_units, activation='relu')(x)\n",
    "        if use_batchnorm:\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) ViT 모델 학습 (단일 실험 예시) / Train the ViT Model (Single Experiment Example)\n",
    "**[KOR]** 위에서 정의한 `build_vit_model`을 사용해 ViT 모델을 하나 구성해 보고, W&B에 로깅합니다.\n",
    "**[ENG]** Use `build_vit_model` to create a ViT model, then train and log metrics to W&B as a single-run example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\GitHub\\mlops\\wandb\\run-20250125_161346-ac6h5q7h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/ac6h5q7h' target=\"_blank\">ViT_single_run</a></strong> to <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/ac6h5q7h' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/ac6h5q7h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTModel.\n",
      "\n",
      "All the weights of TFViTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 2:40 12s/step - accuracy: 0.0625 - loss: 3.10 ━━━━━━━━━━━━━━━━━━━━ 46s 4s/step - accuracy: 0.0859 - loss: 3.0128 ━━━━━━━━━━━━━━━━━━━━ 42s 4s/step - accuracy: 0.1024 - loss: 2.94 ━━━━━━━━━━━━━━━━━━━━ 38s 4s/step - accuracy: 0.1217 - loss: 2.87 ━━━━━━━━━━━━━━━━━━━━ 35s 4s/step - accuracy: 0.1361 - loss: 2.81 ━━━━━━━━━━━━━━━━━━━━ 31s 4s/step - accuracy: 0.1534 - loss: 2.74 ━━━━━━━━━━━━━━━━━━━━ 27s 4s/step - accuracy: 0.1691 - loss: 2.68 ━━━━━━━━━━━━━━━━━━━━ 23s 4s/step - accuracy: 0.1831 - loss: 2.62 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.1944 - loss: 2.57 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.2043 - loss: 2.53 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.2139 - loss: 2.49 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.2230 - loss: 2.4547 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.2315 - loss: 2.419 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.2393 - loss: 2.388 ━━━━━━━━━━━━━━━━━━━━ 69s 4s/step - accuracy: 0.2460 - loss: 2.3615 - val_accuracy: 0.3333 - val_loss: 1.6442\n",
      "Epoch 2/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 51s 4s/step - accuracy: 0.7188 - loss: 0.74 ━━━━━━━━━━━━━━━━━━━━ 46s 4s/step - accuracy: 0.7109 - loss: 0.84 ━━━━━━━━━━━━━━━━━━━━ 42s 4s/step - accuracy: 0.6927 - loss: 0.88 ━━━━━━━━━━━━━━━━━━━━ 38s 4s/step - accuracy: 0.6836 - loss: 0.90 ━━━━━━━━━━━━━━━━━━━━ 35s 4s/step - accuracy: 0.6794 - loss: 0.91 ━━━━━━━━━━━━━━━━━━━━ 31s 4s/step - accuracy: 0.6773 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 27s 4s/step - accuracy: 0.6749 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 23s 4s/step - accuracy: 0.6745 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.6748 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.6751 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.6757 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.6774 - loss: 0.9247 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.6793 - loss: 0.919 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.6811 - loss: 0.915 ━━━━━━━━━━━━━━━━━━━━ 58s 4s/step - accuracy: 0.6827 - loss: 0.9113 - val_accuracy: 0.5882 - val_loss: 1.5154\n",
      "Epoch 3/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 52s 4s/step - accuracy: 0.7500 - loss: 0.66 ━━━━━━━━━━━━━━━━━━━━ 46s 4s/step - accuracy: 0.7578 - loss: 0.63 ━━━━━━━━━━━━━━━━━━━━ 42s 4s/step - accuracy: 0.7517 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 38s 4s/step - accuracy: 0.7591 - loss: 0.58 ━━━━━━━━━━━━━━━━━━━━ 34s 4s/step - accuracy: 0.7685 - loss: 0.56 ━━━━━━━━━━━━━━━━━━━━ 31s 4s/step - accuracy: 0.7689 - loss: 0.56 ━━━━━━━━━━━━━━━━━━━━ 27s 4s/step - accuracy: 0.7700 - loss: 0.56 ━━━━━━━━━━━━━━━━━━━━ 23s 4s/step - accuracy: 0.7700 - loss: 0.56 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.7708 - loss: 0.56 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.7722 - loss: 0.56 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.7733 - loss: 0.56 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.7744 - loss: 0.5659 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.7758 - loss: 0.565 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.7766 - loss: 0.566 ━━━━━━━━━━━━━━━━━━━━ 59s 4s/step - accuracy: 0.7773 - loss: 0.5685 - val_accuracy: 0.7059 - val_loss: 1.4124\n",
      "Epoch 4/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 55s 4s/step - accuracy: 0.8438 - loss: 0.41 ━━━━━━━━━━━━━━━━━━━━ 47s 4s/step - accuracy: 0.8516 - loss: 0.43 ━━━━━━━━━━━━━━━━━━━━ 45s 4s/step - accuracy: 0.8559 - loss: 0.43 ━━━━━━━━━━━━━━━━━━━━ 40s 4s/step - accuracy: 0.8646 - loss: 0.41 ━━━━━━━━━━━━━━━━━━━━ 36s 4s/step - accuracy: 0.8667 - loss: 0.41 ━━━━━━━━━━━━━━━━━━━━ 32s 4s/step - accuracy: 0.8672 - loss: 0.41 ━━━━━━━━━━━━━━━━━━━━ 28s 4s/step - accuracy: 0.8670 - loss: 0.42 ━━━━━━━━━━━━━━━━━━━━ 24s 4s/step - accuracy: 0.8661 - loss: 0.42 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.8655 - loss: 0.43 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.8652 - loss: 0.43 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.8646 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.8639 - loss: 0.4444 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.8638 - loss: 0.444 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.8637 - loss: 0.445 ━━━━━━━━━━━━━━━━━━━━ 60s 4s/step - accuracy: 0.8636 - loss: 0.4455 - val_accuracy: 0.7647 - val_loss: 1.3260\n",
      "Epoch 5/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 53s 4s/step - accuracy: 0.9375 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 48s 4s/step - accuracy: 0.9375 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 43s 4s/step - accuracy: 0.9340 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 39s 4s/step - accuracy: 0.9290 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 35s 4s/step - accuracy: 0.9245 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 31s 4s/step - accuracy: 0.9232 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 27s 4s/step - accuracy: 0.9188 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 23s 4s/step - accuracy: 0.9148 - loss: 0.28 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.9119 - loss: 0.28 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.9098 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.9079 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.9065 - loss: 0.2962 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.9050 - loss: 0.298 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.9036 - loss: 0.301 ━━━━━━━━━━━━━━━━━━━━ 59s 4s/step - accuracy: 0.9024 - loss: 0.3034 - val_accuracy: 0.9216 - val_loss: 1.2263\n",
      "Epoch 6/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 56s 4s/step - accuracy: 0.9062 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 47s 4s/step - accuracy: 0.9062 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 43s 4s/step - accuracy: 0.9097 - loss: 0.28 ━━━━━━━━━━━━━━━━━━━━ 39s 4s/step - accuracy: 0.9128 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 35s 4s/step - accuracy: 0.9140 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 31s 4s/step - accuracy: 0.9161 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 27s 4s/step - accuracy: 0.9179 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 23s 4s/step - accuracy: 0.9170 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.9158 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.9151 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.9153 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.9152 - loss: 0.2736 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.9155 - loss: 0.273 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.9157 - loss: 0.272 ━━━━━━━━━━━━━━━━━━━━ 59s 4s/step - accuracy: 0.9158 - loss: 0.2725 - val_accuracy: 0.9020 - val_loss: 1.1498\n",
      "Epoch 7/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 50s 4s/step - accuracy: 0.9375 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 46s 4s/step - accuracy: 0.9297 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 41s 4s/step - accuracy: 0.9288 - loss: 0.33 ━━━━━━━━━━━━━━━━━━━━ 38s 4s/step - accuracy: 0.9290 - loss: 0.32 ━━━━━━━━━━━━━━━━━━━━ 34s 4s/step - accuracy: 0.9307 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 30s 4s/step - accuracy: 0.9310 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 26s 4s/step - accuracy: 0.9294 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 22s 4s/step - accuracy: 0.9270 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.9254 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.9245 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.9236 - loss: 0.29 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.9230 - loss: 0.2906 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.9225 - loss: 0.288 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.9221 - loss: 0.286 ━━━━━━━━━━━━━━━━━━━━ 59s 4s/step - accuracy: 0.9219 - loss: 0.2852 - val_accuracy: 0.8627 - val_loss: 1.0520\n",
      "Epoch 8/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 52s 4s/step - accuracy: 0.9375 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 46s 4s/step - accuracy: 0.9453 - loss: 0.19 ━━━━━━━━━━━━━━━━━━━━ 42s 4s/step - accuracy: 0.9358 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 38s 4s/step - accuracy: 0.9303 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 35s 4s/step - accuracy: 0.9293 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 31s 4s/step - accuracy: 0.9280 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 27s 4s/step - accuracy: 0.9262 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 23s 4s/step - accuracy: 0.9257 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.9258 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.9260 - loss: 0.19 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.9266 - loss: 0.19 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.9268 - loss: 0.1982 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.9275 - loss: 0.197 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.9281 - loss: 0.196 ━━━━━━━━━━━━━━━━━━━━ 59s 4s/step - accuracy: 0.9287 - loss: 0.1952 - val_accuracy: 0.8824 - val_loss: 0.9207\n",
      "Epoch 9/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 51s 4s/step - accuracy: 0.8750 - loss: 0.30 ━━━━━━━━━━━━━━━━━━━━ 46s 4s/step - accuracy: 0.9062 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 44s 4s/step - accuracy: 0.9167 - loss: 0.22 ━━━━━━━━━━━━━━━━━━━━ 41s 4s/step - accuracy: 0.9238 - loss: 0.21 ━━━━━━━━━━━━━━━━━━━━ 38s 4s/step - accuracy: 0.9303 - loss: 0.20 ━━━━━━━━━━━━━━━━━━━━ 34s 4s/step - accuracy: 0.9341 - loss: 0.19 ━━━━━━━━━━━━━━━━━━━━ 30s 4s/step - accuracy: 0.9365 - loss: 0.18 ━━━━━━━━━━━━━━━━━━━━ 25s 4s/step - accuracy: 0.9381 - loss: 0.18 ━━━━━━━━━━━━━━━━━━━━ 21s 4s/step - accuracy: 0.9392 - loss: 0.18 ━━━━━━━━━━━━━━━━━━━━ 16s 4s/step - accuracy: 0.9400 - loss: 0.18 ━━━━━━━━━━━━━━━━━━━━ 12s 4s/step - accuracy: 0.9408 - loss: 0.18 ━━━━━━━━━━━━━━━━━━━━ 8s 4s/step - accuracy: 0.9416 - loss: 0.1797 ━━━━━━━━━━━━━━━━━━━━ 4s 4s/step - accuracy: 0.9422 - loss: 0.178 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.9426 - loss: 0.177 ━━━━━━━━━━━━━━━━━━━━ 61s 4s/step - accuracy: 0.9430 - loss: 0.1772 - val_accuracy: 0.8627 - val_loss: 0.9053\n",
      "Epoch 10/10\n",
      "14/14 ━━━━━━━━━━━━━━━━━━━━ 55s 4s/step - accuracy: 0.8438 - loss: 0.31 ━━━━━━━━━━━━━━━━━━━━ 47s 4s/step - accuracy: 0.8828 - loss: 0.24 ━━━━━━━━━━━━━━━━━━━━ 42s 4s/step - accuracy: 0.9045 - loss: 0.21 ━━━━━━━━━━━━━━━━━━━━ 40s 4s/step - accuracy: 0.9167 - loss: 0.19 ━━━━━━━━━━━━━━━━━━━━ 36s 4s/step - accuracy: 0.9208 - loss: 0.18 ━━━━━━━━━━━━━━━━━━━━ 32s 4s/step - accuracy: 0.9253 - loss: 0.18 ━━━━━━━━━━━━━━━━━━━━ 28s 4s/step - accuracy: 0.9277 - loss: 0.17 ━━━━━━━━━━━━━━━━━━━━ 23s 4s/step - accuracy: 0.9299 - loss: 0.17 ━━━━━━━━━━━━━━━━━━━━ 19s 4s/step - accuracy: 0.9311 - loss: 0.17 ━━━━━━━━━━━━━━━━━━━━ 15s 4s/step - accuracy: 0.9315 - loss: 0.17 ━━━━━━━━━━━━━━━━━━━━ 11s 4s/step - accuracy: 0.9320 - loss: 0.17 ━━━━━━━━━━━━━━━━━━━━ 7s 4s/step - accuracy: 0.9323 - loss: 0.1711 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.9325 - loss: 0.170 ━━━━━━━━━━━━━━━━━━━━ 0s 4s/step - accuracy: 0.9328 - loss: 0.170 ━━━━━━━━━━━━━━━━━━━━ 60s 4s/step - accuracy: 0.9330 - loss: 0.1700 - val_accuracy: 0.8824 - val_loss: 0.8489\n",
      "2/2 ━━━━━━━━━━━━━━━━━━━━ 3s 4s/step - accuracy: 0.8125 - loss: 0.904 ━━━━━━━━━━━━━━━━━━━━ 0s 3s/step - accuracy: 0.7902 - loss: 0.931 ━━━━━━━━━━━━━━━━━━━━ 7s 3s/step - accuracy: 0.7827 - loss: 0.9412\n",
      "ViT Test Accuracy: 0.7678571343421936\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▄▅▆██▇█▇█</td></tr><tr><td>epoch/val_loss</td><td>█▇▆▅▄▄▃▂▁▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.93677</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.16498</td></tr><tr><td>epoch/val_accuracy</td><td>0.88235</td></tr><tr><td>epoch/val_loss</td><td>0.84893</td></tr><tr><td>test_accuracy</td><td>0.76786</td></tr><tr><td>test_loss</td><td>0.95976</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ViT_single_run</strong> at: <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/ac6h5q7h' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish/runs/ac6h5q7h</a><br> View project at: <a href='https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_vs_CNN_jellyfish</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250125_161346-ac6h5q7h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"ViT_vs_CNN_jellyfish\",\n",
    "    name=\"ViT_single_run\",\n",
    "    reinit=True\n",
    ")\n",
    "\n",
    "vit_model = build_vit_model(\n",
    "    num_classes=num_classes,\n",
    "    num_dense_layers=2,\n",
    "    dense_units=128,\n",
    "    dropout_rate=0.3,\n",
    "    use_batchnorm=True,\n",
    "    base_trainable=False\n",
    ")\n",
    "\n",
    "vit_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "vit_model.fit(\n",
    "    train_batches,\n",
    "    validation_data=val_batches,\n",
    "    epochs=10,\n",
    "     callbacks=[WandbMetricsLogger(log_freq=\"epoch\"),WandbModelCheckpoint(\"model_checkpoint.keras\")] \n",
    ")\n",
    "\n",
    "test_loss, test_acc = vit_model.evaluate(test_batches)\n",
    "wandb.log({\"test_loss\": test_loss, \"test_accuracy\": test_acc})\n",
    "print(\"ViT Test Accuracy:\", test_acc)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) W&B Sweep 설정 예시 (sweep.yaml) / W&B Sweep Configuration Example\n",
    "**[KOR]** 다양한 하이퍼파라미터(레이어 수, Dropout 비율, BatchNorm 여부 등)를 탐색하기 위한 예시 스윕 설정입니다.\n",
    "**[ENG]** An example sweep configuration for exploring various hyperparameters (number of Dense layers, dropout rate, batch normalization, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "method: bayes\n",
      "metric:\n",
      "  name: val_accuracy\n",
      "  goal: maximize\n",
      "parameters:\n",
      "  num_dense_layers:\n",
      "    values: [2, 3]\n",
      "  dense_units:\n",
      "    values: [64, 128, 256]\n",
      "  dropout_rate:\n",
      "    values: [0.2, 0.3, 0.5]\n",
      "  use_batchnorm:\n",
      "    values: [true, false]\n",
      "  base_trainable:\n",
      "    values: [false, true]\n",
      "  learning_rate:\n",
      "    values: [1e-2, 1e-3, 1e-4]\n",
      "  batch_size:\n",
      "    values: [16, 32]\n",
      "  epochs:\n",
      "    values: [5, 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sweep_config = '''\n",
    "method: bayes\n",
    "metric:\n",
    "  name: val_accuracy\n",
    "  goal: maximize\n",
    "parameters:\n",
    "  num_dense_layers:\n",
    "    values: [2, 3]\n",
    "  dense_units:\n",
    "    values: [64, 128, 256]\n",
    "  dropout_rate:\n",
    "    values: [0.2, 0.3, 0.5]\n",
    "  use_batchnorm:\n",
    "    values: [true, false]\n",
    "  base_trainable:\n",
    "    values: [false, true]\n",
    "  learning_rate:\n",
    "    values: [1e-2, 1e-3, 1e-4]\n",
    "  batch_size:\n",
    "    values: [16, 32]\n",
    "  epochs:\n",
    "    values: [5, 10]\n",
    "'''\n",
    "\n",
    "print(sweep_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9) Sweep 트레이닝 함수 / Sweep Training Function\n",
    "**[KOR]** Sweep 에이전트가 각 실험마다 호출할 함수입니다. 여러 조합을 자동 시도하며 결과를 W&B에 기록합니다.\n",
    "**[ENG]** This function is called by the sweep agent for each experiment, automatically trying different combinations and logging results to W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        # Ensure batch_size is set correctly\n",
    "        current_train_batches = train_ds.batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        current_val_batches = val_ds.batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        current_test_batches = test_ds.batch(config.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        model = build_vit_model(\n",
    "            num_classes=num_classes,\n",
    "            num_dense_layers=config.num_dense_layers,\n",
    "            dense_units=config.dense_units,\n",
    "            dropout_rate=config.dropout_rate,\n",
    "            use_batchnorm=config.use_batchnorm,\n",
    "            base_trainable=config.base_trainable\n",
    "        )\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            current_train_batches,\n",
    "            validation_data=current_val_batches,\n",
    "            epochs=config.epochs,\n",
    "            callbacks=[WandbMetricsLogger(log_freq=\"epoch\"), WandbModelCheckpoint(\"model_checkpoint.keras\")]\n",
    "        )\n",
    "\n",
    "        test_loss, test_acc = model.evaluate(current_test_batches)\n",
    "        wandb.log({\"test_loss\": test_loss, \"test_accuracy\": test_acc})\n",
    "        print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10) Sweep 실행 / Launch the Sweep\n",
    "**[KOR]** 아래 코드(또는 CLI 명령어)를 통해 sweep을 생성하고, 에이전트를 실행하면 다양한 아키텍처 및 HP 조합이 자동으로 탐색됩니다.\n",
    "**[ENG]** Use the code (or CLI commands) below to create a sweep and run an agent, automatically exploring multiple architecture and hyperparameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 7jsde31a\n",
      "Sweep URL: https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 6d46smmx with config:\n",
      "wandb: \tbase_trainable: True\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdense_units: 128\n",
      "wandb: \tdropout_rate: 0.5\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tlearning_rate: 0.001\n",
      "wandb: \tnum_dense_layers: 3\n",
      "wandb: \tuse_batchnorm: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\GitHub\\mlops\\wandb\\run-20250127_011124-6d46smmx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/6d46smmx' target=\"_blank\">flowing-sweep-1</a></strong> to <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/6d46smmx' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/6d46smmx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTModel.\n",
      "\n",
      "All the weights of TFViTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flowing-sweep-1</strong> at: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/6d46smmx' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/6d46smmx</a><br> View project at: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250127_011124-6d46smmx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 6d46smmx errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n",
      "\n",
      "wandb: ERROR Run 6d46smmx errored:\n",
      "wandb: ERROR Traceback (most recent call last):\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "wandb: ERROR     self._function()\n",
      "wandb: ERROR   File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "wandb: ERROR     model.fit(\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "wandb: ERROR     raise e.with_traceback(filtered_tb) from None\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "wandb: ERROR     raise ValueError(\n",
      "wandb: ERROR ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n",
      "wandb: ERROR \n",
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 9dkkkbz1 with config:\n",
      "wandb: \tbase_trainable: True\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tdense_units: 128\n",
      "wandb: \tdropout_rate: 0.3\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tlearning_rate: 0.0001\n",
      "wandb: \tnum_dense_layers: 3\n",
      "wandb: \tuse_batchnorm: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\GitHub\\mlops\\wandb\\run-20250127_011139-9dkkkbz1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/9dkkkbz1' target=\"_blank\">crisp-sweep-2</a></strong> to <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/9dkkkbz1' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/9dkkkbz1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTModel.\n",
      "\n",
      "All the weights of TFViTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crisp-sweep-2</strong> at: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/9dkkkbz1' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/9dkkkbz1</a><br> View project at: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250127_011139-9dkkkbz1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 9dkkkbz1 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n",
      "\n",
      "wandb: ERROR Run 9dkkkbz1 errored:\n",
      "wandb: ERROR Traceback (most recent call last):\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "wandb: ERROR     self._function()\n",
      "wandb: ERROR   File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "wandb: ERROR     model.fit(\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "wandb: ERROR     raise e.with_traceback(filtered_tb) from None\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "wandb: ERROR     raise ValueError(\n",
      "wandb: ERROR ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n",
      "wandb: ERROR \n",
      "wandb: Agent Starting Run: pd1ttb82 with config:\n",
      "wandb: \tbase_trainable: True\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdense_units: 128\n",
      "wandb: \tdropout_rate: 0.2\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tlearning_rate: 0.001\n",
      "wandb: \tnum_dense_layers: 2\n",
      "wandb: \tuse_batchnorm: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\User\\Documents\\GitHub\\mlops\\wandb\\run-20250127_011145-pd1ttb82</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/pd1ttb82' target=\"_blank\">dutiful-sweep-3</a></strong> to <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/sweeps/7jsde31a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/pd1ttb82' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/pd1ttb82</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTModel.\n",
      "\n",
      "All the weights of TFViTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-3</strong> at: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/pd1ttb82' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing/runs/pd1ttb82</a><br> View project at: <a href='https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing' target=\"_blank\">https://wandb.ai/realx1212-aijosh/ViT_jellyfish_HPtuing</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250127_011145-pd1ttb82\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run pd1ttb82 errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n",
      "\n",
      "wandb: ERROR Run pd1ttb82 errored:\n",
      "wandb: ERROR Traceback (most recent call last):\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 306, in _run_job\n",
      "wandb: ERROR     self._function()\n",
      "wandb: ERROR   File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27064\\1046017399.py\", line 26, in train_sweep\n",
      "wandb: ERROR     model.fit(\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "wandb: ERROR     raise e.with_traceback(filtered_tb) from None\n",
      "wandb: ERROR   File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 245, in assert_input_compatibility\n",
      "wandb: ERROR     raise ValueError(\n",
      "wandb: ERROR ValueError: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, None, 224, 224, 3)\n",
      "wandb: ERROR \n",
      "Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "wandb: ERROR Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "wandb: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
     ]
    }
   ],
   "source": [
    "# (주의) 실제로 실행할 때 주석 해제\n",
    "import yaml\n",
    "sweep_config_dict = yaml.safe_load(sweep_config)\n",
    "sweep_id = wandb.sweep(sweep_config_dict, project=\"ViT_jellyfish_HPtuing\")\n",
    "wandb.agent(sweep_id, function=train_sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 요약 / Summary\n",
    "**[KOR]** 위 노트북을 통해 전통적인 CNN과 사전 학습된 ViT 기반 모델을 모두 학습해보고, W&B의 Sweep 기능으로 아키텍처 및 하이퍼파라미터를 자동 탐색할 수 있습니다.\n",
    "**[ENG]** This notebook allows you to train both a traditional CNN and a pretrained ViT model, and use W&B Sweeps to automatically search for optimal architectures and hyperparameters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "vit_cnn_flowers_sweeps.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
